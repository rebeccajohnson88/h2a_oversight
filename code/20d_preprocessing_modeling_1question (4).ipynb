{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5e5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/euniceliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/euniceliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import yaml\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Google Cloud Language Translation API\n",
    "# We're using the basic version here == \"v2\" \n",
    "from google.cloud import translate_v2\n",
    "\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "## nltk imports\n",
    "# ! pip install gensim\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58714bc9",
   "metadata": {},
   "source": [
    "# Dataset used in this notebook\n",
    "- read in: combined_certificate_postings.csv (the merged data that contains the job addendums and the CASE_STATUS variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e7b08",
   "metadata": {},
   "source": [
    "# Major tasks accomplished in this notebook\n",
    "- 1) Classify the outcome variables (CASE_STATUS) into binary 0,1\n",
    "- 2) Pre-process the job addendums\n",
    "- 3) Create a job posting classifier Using TF-IDF \n",
    "- 4) Create and run a Multinomial Naive Bayes model to see the prediction of CASE_STATUS by the text features\n",
    "- 5) Compare the result of Multinomial Naive Bayes model that use TF-IDF score vs count\n",
    "- 6) Explore the Bernoulli Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b5689",
   "metadata": {},
   "source": [
    "# Why are these tasks important\n",
    "- Provide insights on how the job addendums help predict the Case_status  \n",
    "- Showcase the strength of incorporating TF-IDF score into my model which support that my model (creating a job posting classifier using TF-IDF scores and create and run a Multinomial Naive Bayes model) is the better choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72249c",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13662484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropbox\n",
    "dropbox_general = \"/Users/euniceliu/Dropbox (Dartmouth College)/\"\n",
    "DROPBOX_DATA_PATH = os.path.join(dropbox_general,\n",
    "                                \"qss20_finalproj_rawdata/summerwork/\")\n",
    "DATA_RAW_DIR = os.path.join(DROPBOX_DATA_PATH, \"raw/\")\n",
    "DATA_ID_DIR = os.path.join(DROPBOX_DATA_PATH, \"intermediate/\")\n",
    "WRITEFOLDER = os.path.join(DATA_ID_DIR)\n",
    "# github\n",
    "GITHUB_DATA_PATH = \"../data/raw_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e4d55",
   "metadata": {},
   "source": [
    "## Pre-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d378c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>combined_job_postings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>H-300-20265-835437</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>the most economical and reasonable charges for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>H-300-20260-827678</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Incoming transportation and subsistence advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>H-300-20260-827308</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>An employee may be terminated for just cause. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>H-300-20258-821801</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>ELECTRONIC COMMUNICATION\\nCell phones, along w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>H-300-20258-821682</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Employee Expectations and Behavior Continued:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         CASE_NUMBER                           CASE_STATUS  \\\n",
       "0           0  H-300-20265-835437  Determination Issued - Certification   \n",
       "1           1  H-300-20260-827678  Determination Issued - Certification   \n",
       "2           2  H-300-20260-827308  Determination Issued - Certification   \n",
       "3           3  H-300-20258-821801  Determination Issued - Certification   \n",
       "4           4  H-300-20258-821682  Determination Issued - Certification   \n",
       "\n",
       "                               combined_job_postings  \n",
       "0  the most economical and reasonable charges for...  \n",
       "1  Incoming transportation and subsistence advanc...  \n",
       "2  An employee may be terminated for just cause. ...  \n",
       "3  ELECTRONIC COMMUNICATION\\nCell phones, along w...  \n",
       "4  Employee Expectations and Behavior Continued:\\...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the combined dataset\n",
    "combined_certificate_postings= pd.read_csv(DATA_ID_DIR+'combined_certificate_postings.csv')\n",
    "combined_certificate_postings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1337a",
   "metadata": {},
   "source": [
    "### Classify the outcome variables CASE_STATUS into 0 or 1 binary outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cd6bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Determination Issued - Certification',\n",
       "       'Determination Issued - Denied',\n",
       "       'Determination Issued - Partial Certification',\n",
       "       'Determination Issued - Certification (Expired)',\n",
       "       'Determination Issued - Partial Certification (Expired)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Determination Issued - Certification                      11165\n",
       "Determination Issued - Certification (Expired)             1812\n",
       "Determination Issued - Denied                               168\n",
       "Determination Issued - Partial Certification                 80\n",
       "Determination Issued - Partial Certification (Expired)       25\n",
       "Name: CASE_STATUS, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1) check the category\n",
    "combined_certificate_postings.CASE_STATUS.unique()\n",
    "combined_certificate_postings['CASE_STATUS'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca97531",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Classify the CASE_STATUS into binary variables (0 and 1)\n",
    "## if certification +  certification (expired) >> 1 (approved cases)\n",
    "## if partial certification + partial certification (expired) + denied (no approved cases)\n",
    "combined_certificate_postings['CASE_OUTCOME'] = np.where(combined_certificate_postings['CASE_STATUS'].str.contains('Denied|Partial'), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17af6d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Determination Issued - Certification                      11165\n",
       "Determination Issued - Certification (Expired)             1812\n",
       "Determination Issued - Denied                               168\n",
       "Determination Issued - Partial Certification                 80\n",
       "Determination Issued - Partial Certification (Expired)       25\n",
       "Name: CASE_STATUS, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1    12977\n",
       "0      273\n",
       "Name: CASE_OUTCOME, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3) check if coding to binary vairable work\n",
    "combined_certificate_postings['CASE_OUTCOME'].unique()\n",
    "combined_certificate_postings['CASE_STATUS'].value_counts()\n",
    "combined_certificate_postings['CASE_OUTCOME'].value_counts()\n",
    "# the number does add up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1f7bf",
   "metadata": {},
   "source": [
    "###  Randomly Select 1000 Our Certified Case (Labelled as One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c9ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12977, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(273, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## subset to certified case (label as 1) and not certified case (label as 0)\n",
    "certified = combined_certificate_postings[combined_certificate_postings[\"CASE_OUTCOME\"]==1]\n",
    "notcertified = combined_certificate_postings[combined_certificate_postings[\"CASE_OUTCOME\"]==0]\n",
    "## show be 12977 rows\n",
    "certified.shape\n",
    "## show be 273 rows\n",
    "notcertified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b25a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>combined_job_postings</th>\n",
       "      <th>CASE_OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>9758</td>\n",
       "      <td>H-300-19330-167821</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Employer will furnish free and convenient cook...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>H-300-20212-743475</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>The employer will also provide advance subsist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>4021</td>\n",
       "      <td>H-300-20064-374924</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>All workers will be subject to a trial period ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>4286</td>\n",
       "      <td>H-300-20057-353443</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Stake, string, tie and thin crops, as instruct...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>10339</td>\n",
       "      <td>H-300-19312-136148</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>The employer retains possession and control of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         CASE_NUMBER                           CASE_STATUS  \\\n",
       "9758         9758  H-300-19330-167821  Determination Issued - Certification   \n",
       "418           418  H-300-20212-743475  Determination Issued - Certification   \n",
       "4021         4021  H-300-20064-374924  Determination Issued - Certification   \n",
       "4286         4286  H-300-20057-353443  Determination Issued - Certification   \n",
       "10339       10339  H-300-19312-136148  Determination Issued - Certification   \n",
       "\n",
       "                                   combined_job_postings  CASE_OUTCOME  \n",
       "9758   Employer will furnish free and convenient cook...             1  \n",
       "418    The employer will also provide advance subsist...             1  \n",
       "4021   All workers will be subject to a trial period ...             1  \n",
       "4286   Stake, string, tie and thin crops, as instruct...             1  \n",
       "10339  The employer retains possession and control of...             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## randomly select 1000 positive cases\n",
    "certified_1000 = certified.sample(n = 1000)\n",
    "certified_1000.shape\n",
    "certified_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c97846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## rowbind back to our notcertified dataset\n",
    "combined_selected = pd.concat([certified_1000, notcertified])\n",
    "combined_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727af0a0",
   "metadata": {},
   "source": [
    "## Run Text Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a5ef0",
   "metadata": {},
   "source": [
    "### Convert characters to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b553ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08867788314819336 seconds\n"
     ]
    }
   ],
   "source": [
    "## lower case\n",
    "start_time = time.time()\n",
    "combined_selected['postings_lower']= combined_selected['combined_job_postings'].apply(lambda x: x.lower())\n",
    "print(\"%s seconds\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed22aa",
   "metadata": {},
   "source": [
    "### Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8cfc1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.528738975524902 seconds\n"
     ]
    }
   ],
   "source": [
    "## tokenized\n",
    "start_time = time.time()\n",
    "combined_selected['postings_tokenized'] = combined_selected['postings_lower'].apply(word_tokenize)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991a64e",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786163e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.894984245300293 seconds\n"
     ]
    }
   ],
   "source": [
    "## define stopwords\n",
    "other_stopwords = [\"after\", \"before\", \"employer\", \"employ\", \"job\", \"although\", \"provide\", \"complete\",\"hour\",\"time\",\n",
    "                  \"begin\",\"list\",\"require\",\"task\",\"transportation\",\"worker\",\"workers\",\"working\",\"work\",\"worked\",\"works\"]\n",
    "\n",
    "list_stopwords = stopwords.words(\"english\")+ other_stopwords\n",
    "\n",
    "stopwords_complete = list_stopwords + other_stopwords\n",
    "start_time = time.time()\n",
    "## remove those\n",
    "combined_selected['posting_without_stopwords']=combined_selected['postings_tokenized'].apply(lambda x: [word for word in x if word not in stopwords_complete])\n",
    "\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb221d84",
   "metadata": {},
   "source": [
    "### Perform Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e4f355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.47009301185608 seconds\n"
     ]
    }
   ],
   "source": [
    "## stemming \n",
    "start_time = time.time()\n",
    "porter = PorterStemmer()\n",
    "combined_selected['stemmed'] = combined_selected['posting_without_stopwords'].apply(lambda x: [porter.stem(y)for y in x]) # Stem every word.\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c264fdf",
   "metadata": {},
   "source": [
    "### Remove words that is less than 3 characters and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edf23538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7479     [inbound, cost, first, workweek, employ, exten...\n",
       "12714    [provid, airplan, charter, oper, vehicl, commo...\n",
       "6546     [offer, seven, week, farmwork, must, perform, ...\n",
       "9490     [shall, form, farm, vehicl, common, mean, plac...\n",
       "9142     [qualifi, inbound, outbound, travel, reimburs,...\n",
       "                               ...                        \n",
       "13245              [paid, done, arizona, done, california]\n",
       "13246    [rule, guidanc, regard, accept, conduct, stand...\n",
       "13247    [upon, complet, contract, dismiss, earlier, re...\n",
       "13248    [april, middl, irrig, detail, around, farm, us...\n",
       "13249    [hous, offer, hous, provid, hous, clean, compl...\n",
       "Name: cleaned, Length: 1273, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## keep isalpha() and the length of the word that is greater than 3\n",
    "combined_selected['cleaned']=combined_selected['stemmed'].apply(lambda x: [word for word in x if word.isalpha() and len(word)>3])\n",
    "combined_selected['cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53dc019",
   "metadata": {},
   "source": [
    "### Join back each word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a692c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7479     inbound cost first workweek employ extent shif...\n",
       "12714    provid airplan charter oper vehicl common mean...\n",
       "6546     offer seven week farmwork must perform seven w...\n",
       "9490     shall form farm vehicl common mean place provi...\n",
       "9142     qualifi inbound outbound travel reimburs entit...\n",
       "                               ...                        \n",
       "13245                    paid done arizona done california\n",
       "13246    rule guidanc regard accept conduct standard ge...\n",
       "13247    upon complet contract dismiss earlier reason c...\n",
       "13248    april middl irrig detail around farm usag plum...\n",
       "13249    hous offer hous provid hous clean complianc ap...\n",
       "Name: cleaned, Length: 1273, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_selected['cleaned']=combined_selected['cleaned'].apply(lambda x: \" \".join(x))\n",
    "combined_selected['cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5ba17",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211a00c",
   "metadata": {},
   "source": [
    "### Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe08b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>combined_job_postings</th>\n",
       "      <th>CASE_OUTCOME</th>\n",
       "      <th>postings_lower</th>\n",
       "      <th>postings_tokenized</th>\n",
       "      <th>posting_without_stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>6283</td>\n",
       "      <td>H-300-20020-263904</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>All workers are required to follow common sani...</td>\n",
       "      <td>1</td>\n",
       "      <td>all workers are required to follow common sani...</td>\n",
       "      <td>[all, workers, are, required, to, follow, comm...</td>\n",
       "      <td>[required, follow, common, sanitary, practices...</td>\n",
       "      <td>[requir, follow, common, sanitari, practic, ti...</td>\n",
       "      <td>requir follow common sanitari practic time par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1350</td>\n",
       "      <td>H-300-20163-646331</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Incoming transportation and subsistence advanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>incoming transportation and subsistence advanc...</td>\n",
       "      <td>[incoming, transportation, and, subsistence, a...</td>\n",
       "      <td>[incoming, subsistence, advanced/paid, 50, %, ...</td>\n",
       "      <td>[incom, subsist, advanced/paid, 50, %, complet...</td>\n",
       "      <td>incom subsist complet contract deduct accord a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>9862</td>\n",
       "      <td>H-300-19326-162101</td>\n",
       "      <td>Determination Issued - Certification (Expired)</td>\n",
       "      <td>H-2A workers must depart the United States at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>h-2a workers must depart the united states at ...</td>\n",
       "      <td>[h-2a, workers, must, depart, the, united, sta...</td>\n",
       "      <td>[h-2a, must, depart, united, states, completio...</td>\n",
       "      <td>[h-2a, must, depart, unit, state, complet, con...</td>\n",
       "      <td>must depart unit state complet contract period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8840</th>\n",
       "      <td>8840</td>\n",
       "      <td>H-300-19350-199601</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>ELECTRONIC COMMUNICATION\\nCell phones along wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>electronic communication\\ncell phones along wi...</td>\n",
       "      <td>[electronic, communication, cell, phones, alon...</td>\n",
       "      <td>[electronic, communication, cell, phones, alon...</td>\n",
       "      <td>[electron, commun, cell, phone, along, suffici...</td>\n",
       "      <td>electron commun cell phone along suffici minut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>10637</td>\n",
       "      <td>H-300-19302-115364</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>Incoming transportation and subsistence advanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>incoming transportation and subsistence advanc...</td>\n",
       "      <td>[incoming, transportation, and, subsistence, a...</td>\n",
       "      <td>[incoming, subsistence, advanced/paid, 50, %, ...</td>\n",
       "      <td>[incom, subsist, advanced/paid, 50, %, complet...</td>\n",
       "      <td>incom subsist complet contract deduct accord a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         CASE_NUMBER  \\\n",
       "6283         6283  H-300-20020-263904   \n",
       "1350         1350  H-300-20163-646331   \n",
       "9862         9862  H-300-19326-162101   \n",
       "8840         8840  H-300-19350-199601   \n",
       "10637       10637  H-300-19302-115364   \n",
       "\n",
       "                                          CASE_STATUS  \\\n",
       "6283             Determination Issued - Certification   \n",
       "1350             Determination Issued - Certification   \n",
       "9862   Determination Issued - Certification (Expired)   \n",
       "8840             Determination Issued - Certification   \n",
       "10637            Determination Issued - Certification   \n",
       "\n",
       "                                   combined_job_postings  CASE_OUTCOME  \\\n",
       "6283   All workers are required to follow common sani...             1   \n",
       "1350   Incoming transportation and subsistence advanc...             1   \n",
       "9862   H-2A workers must depart the United States at ...             1   \n",
       "8840   ELECTRONIC COMMUNICATION\\nCell phones along wi...             1   \n",
       "10637  Incoming transportation and subsistence advanc...             1   \n",
       "\n",
       "                                          postings_lower  \\\n",
       "6283   all workers are required to follow common sani...   \n",
       "1350   incoming transportation and subsistence advanc...   \n",
       "9862   h-2a workers must depart the united states at ...   \n",
       "8840   electronic communication\\ncell phones along wi...   \n",
       "10637  incoming transportation and subsistence advanc...   \n",
       "\n",
       "                                      postings_tokenized  \\\n",
       "6283   [all, workers, are, required, to, follow, comm...   \n",
       "1350   [incoming, transportation, and, subsistence, a...   \n",
       "9862   [h-2a, workers, must, depart, the, united, sta...   \n",
       "8840   [electronic, communication, cell, phones, alon...   \n",
       "10637  [incoming, transportation, and, subsistence, a...   \n",
       "\n",
       "                               posting_without_stopwords  \\\n",
       "6283   [required, follow, common, sanitary, practices...   \n",
       "1350   [incoming, subsistence, advanced/paid, 50, %, ...   \n",
       "9862   [h-2a, must, depart, united, states, completio...   \n",
       "8840   [electronic, communication, cell, phones, alon...   \n",
       "10637  [incoming, subsistence, advanced/paid, 50, %, ...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "6283   [requir, follow, common, sanitari, practic, ti...   \n",
       "1350   [incom, subsist, advanced/paid, 50, %, complet...   \n",
       "9862   [h-2a, must, depart, unit, state, complet, con...   \n",
       "8840   [electron, commun, cell, phone, along, suffici...   \n",
       "10637  [incom, subsist, advanced/paid, 50, %, complet...   \n",
       "\n",
       "                                                 cleaned  \n",
       "6283   requir follow common sanitari practic time par...  \n",
       "1350   incom subsist complet contract deduct accord a...  \n",
       "9862   must depart unit state complet contract period...  \n",
       "8840   electron commun cell phone along suffici minut...  \n",
       "10637  incom subsist complet contract deduct accord a...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "0     273\n",
       "Name: CASE_OUTCOME, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_selected.head()\n",
    "combined_selected['CASE_OUTCOME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2e288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test=train_test_split(combined_selected,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4952c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>combined_job_postings</th>\n",
       "      <th>CASE_OUTCOME</th>\n",
       "      <th>postings_lower</th>\n",
       "      <th>postings_tokenized</th>\n",
       "      <th>posting_without_stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>6191</td>\n",
       "      <td>H-300-20021-265051</td>\n",
       "      <td>Determination Issued - Partial Certification (...</td>\n",
       "      <td>Employer will train workers. Training will inc...</td>\n",
       "      <td>0</td>\n",
       "      <td>employer will train workers. training will inc...</td>\n",
       "      <td>[employer, will, train, workers, ., training, ...</td>\n",
       "      <td>[train, ., training, include, limited, safety,...</td>\n",
       "      <td>[train, ., train, includ, limit, safeti, train...</td>\n",
       "      <td>train train includ limit safeti train protect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>10450</td>\n",
       "      <td>H-300-19309-126181</td>\n",
       "      <td>Determination Issued - Certification (Expired)</td>\n",
       "      <td>Harassment: The employer committed to providin...</td>\n",
       "      <td>1</td>\n",
       "      <td>harassment: the employer committed to providin...</td>\n",
       "      <td>[harassment, :, the, employer, committed, to, ...</td>\n",
       "      <td>[harassment, :, committed, providing, safe, ,,...</td>\n",
       "      <td>[harass, :, commit, provid, safe, ,, flexibl, ...</td>\n",
       "      <td>harass commit provid safe flexibl respect envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10419</th>\n",
       "      <td>10419</td>\n",
       "      <td>H-300-19310-129885</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>...incurred by the worker for transportation a...</td>\n",
       "      <td>1</td>\n",
       "      <td>...incurred by the worker for transportation a...</td>\n",
       "      <td>[..., incurred, by, the, worker, for, transpor...</td>\n",
       "      <td>[..., incurred, daily, subsistence, place, com...</td>\n",
       "      <td>[..., incur, daili, subsist, place, come, ,, w...</td>\n",
       "      <td>incur daili subsist place come whether abroad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10724</th>\n",
       "      <td>10724</td>\n",
       "      <td>H-300-19298-110492</td>\n",
       "      <td>Determination Issued - Certification (Expired)</td>\n",
       "      <td>No deductions except those required by law wil...</td>\n",
       "      <td>1</td>\n",
       "      <td>no deductions except those required by law wil...</td>\n",
       "      <td>[no, deductions, except, those, required, by, ...</td>\n",
       "      <td>[deductions, except, required, law, made, brin...</td>\n",
       "      <td>[deduct, except, requir, law, made, bring, 's,...</td>\n",
       "      <td>deduct except requir made bring earn feder min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>12747</td>\n",
       "      <td>H-300-20329-926801</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>TERMINATIONS:  The employer may terminate the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>terminations:  the employer may terminate the ...</td>\n",
       "      <td>[terminations, :, the, employer, may, terminat...</td>\n",
       "      <td>[terminations, :, may, terminate, notification...</td>\n",
       "      <td>[termin, :, may, termin, notif, appropri, stat...</td>\n",
       "      <td>termin termin notif appropri state feder agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         CASE_NUMBER  \\\n",
       "6191         6191  H-300-20021-265051   \n",
       "10450       10450  H-300-19309-126181   \n",
       "10419       10419  H-300-19310-129885   \n",
       "10724       10724  H-300-19298-110492   \n",
       "12747       12747  H-300-20329-926801   \n",
       "\n",
       "                                             CASE_STATUS  \\\n",
       "6191   Determination Issued - Partial Certification (...   \n",
       "10450     Determination Issued - Certification (Expired)   \n",
       "10419               Determination Issued - Certification   \n",
       "10724     Determination Issued - Certification (Expired)   \n",
       "12747               Determination Issued - Certification   \n",
       "\n",
       "                                   combined_job_postings  CASE_OUTCOME  \\\n",
       "6191   Employer will train workers. Training will inc...             0   \n",
       "10450  Harassment: The employer committed to providin...             1   \n",
       "10419  ...incurred by the worker for transportation a...             1   \n",
       "10724  No deductions except those required by law wil...             1   \n",
       "12747  TERMINATIONS:  The employer may terminate the ...             1   \n",
       "\n",
       "                                          postings_lower  \\\n",
       "6191   employer will train workers. training will inc...   \n",
       "10450  harassment: the employer committed to providin...   \n",
       "10419  ...incurred by the worker for transportation a...   \n",
       "10724  no deductions except those required by law wil...   \n",
       "12747  terminations:  the employer may terminate the ...   \n",
       "\n",
       "                                      postings_tokenized  \\\n",
       "6191   [employer, will, train, workers, ., training, ...   \n",
       "10450  [harassment, :, the, employer, committed, to, ...   \n",
       "10419  [..., incurred, by, the, worker, for, transpor...   \n",
       "10724  [no, deductions, except, those, required, by, ...   \n",
       "12747  [terminations, :, the, employer, may, terminat...   \n",
       "\n",
       "                               posting_without_stopwords  \\\n",
       "6191   [train, ., training, include, limited, safety,...   \n",
       "10450  [harassment, :, committed, providing, safe, ,,...   \n",
       "10419  [..., incurred, daily, subsistence, place, com...   \n",
       "10724  [deductions, except, required, law, made, brin...   \n",
       "12747  [terminations, :, may, terminate, notification...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "6191   [train, ., train, includ, limit, safeti, train...   \n",
       "10450  [harass, :, commit, provid, safe, ,, flexibl, ...   \n",
       "10419  [..., incur, daili, subsist, place, come, ,, w...   \n",
       "10724  [deduct, except, requir, law, made, bring, 's,...   \n",
       "12747  [termin, :, may, termin, notif, appropri, stat...   \n",
       "\n",
       "                                                 cleaned  \n",
       "6191   train train includ limit safeti train protect ...  \n",
       "10450  harass commit provid safe flexibl respect envi...  \n",
       "10419  incur daili subsist place come whether abroad ...  \n",
       "10724  deduct except requir made bring earn feder min...  \n",
       "12747  termin termin notif appropri state feder agenc...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebc0af",
   "metadata": {},
   "source": [
    "## Create a job postings classifier using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64d9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb277ab7",
   "metadata": {},
   "source": [
    "### Write transform and fit into a function so the code looks neater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a586343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_topwords(df,kind):\n",
    "    if kind==\"test\":\n",
    "        tf_idf = vectorizer.transform(df['cleaned'])\n",
    "    elif kind==\"train\":\n",
    "        tf_idf = vectorizer.fit_transform(df['cleaned'])\n",
    "        tf_idf = vectorizer.transform(df['cleaned'])\n",
    "    else:\n",
    "        return (\"wrong input\")\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adcb086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf=tfidf_topwords(train,\"train\")\n",
    "X_test_tf=tfidf_topwords(test,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dc9bb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 2696)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b073cecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 2696)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66a2d2",
   "metadata": {},
   "source": [
    "## Create and run a Multinomial Naive Bayes model + Modeling Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91d6c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y value\n",
    "train_y=train[\"CASE_OUTCOME\"]\n",
    "test_y=test[\"CASE_OUTCOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2010f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Certified       0.86      0.11      0.19        55\n",
      "      Denied       0.80      0.99      0.89       200\n",
      "\n",
      "    accuracy                           0.80       255\n",
      "   macro avg       0.83      0.55      0.54       255\n",
      "weighted avg       0.81      0.80      0.74       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "print(metrics.classification_report(test_y, y_pred, target_names=['Certified', 'Denied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c633f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[  6  49]\n",
      " [  1 199]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cd338",
   "metadata": {},
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33230e",
   "metadata": {},
   "source": [
    "## Findings using TF-IDF to create a job posting classifier & run a Multinomial Naive Bayes model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797be1ea",
   "metadata": {},
   "source": [
    "### As presented in the cells above, the data is extremely imbalanced (with 12977 positive cases (fully certified) and 273 negative cases (not fully certified & denied)). In this case, extra wrangling of the data is required or else the result of the predictive model would not be informative because the predictors will highly likely to predict any given test sample to the positive group which also means that the precision and recall will be very high. On the other hand, in this situation, the precision and recall would be very low for the negative cases. Thus, I randomly sampled the postive cases (case status that is fully certified) to only include 1000 cases to miminize the effect of imbalanced dataset. The model works better  as the accuracy is 0.8 and the weighted average for precision, recall and f1-score is relatively high which is respectively 0.81, 0.80 and 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be887758",
   "metadata": {},
   "source": [
    "# Extra exploration using the Bernoulli Naive Bayes model and Count Vectorizer + Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4040e07e",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac0093cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "CVectorizer=CountVectorizer(ngram_range=(1,3),min_df=5)\n",
    "uni_bigrams=CVectorizer.fit(train['cleaned'])\n",
    "X_train_vecotrized=uni_bigrams.transform(train['cleaned'])\n",
    "X_test_vecotrized=CVectorizer.transform(test['cleaned'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769dd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train[\"CASE_OUTCOME\"]\n",
    "test_y=test[\"CASE_OUTCOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfac4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Certified       0.34      0.89      0.49        55\n",
      "      Denied       0.95      0.53      0.68       200\n",
      "\n",
      "    accuracy                           0.60       255\n",
      "   macro avg       0.64      0.71      0.58       255\n",
      "weighted avg       0.82      0.60      0.64       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "BernoulliNB_classifier = BernoulliNB()\n",
    "BernoulliNB_classifier.fit(X_train_vecotrized, train_y)\n",
    "y_pred = BernoulliNB_classifier.predict(X_test_vecotrized)\n",
    "print(metrics.classification_report(test_y, y_pred, target_names=['Certified', 'Denied']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5692fe1",
   "metadata": {},
   "source": [
    "## Count Vectorizer + Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db9e0eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Certified       0.35      0.80      0.49        55\n",
      "      Denied       0.92      0.60      0.73       200\n",
      "\n",
      "    accuracy                           0.64       255\n",
      "   macro avg       0.64      0.70      0.61       255\n",
      "weighted avg       0.79      0.64      0.67       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_vecotrized, train_y)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_vecotrized)\n",
    "print(metrics.classification_report(test_y, y_pred, target_names=['Certified', 'Denied']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91648fe9",
   "metadata": {},
   "source": [
    "### After running the Bernoulli Naive Bayes model, I recognize that it would not make sense to make direct comparison of that with the Multinomial Naive Bayes model since I not only use different model but also the vectorizer is different. In this case, it is hard to analyze whether the better/worse performance of the model is due to the vectorizer choice or the model choice. Thus, I run another Multinomial Naive Bayes model but instead of using the TF-IDF score for words, I decided to use the count of the words for text classification because I am interested to know whether my initial choice of going for term frequency-inverse document frequency (TF-IDF) is the correct choice. We can see that the performace of model is better in the first model (the one using TF-IDF) as the accuracy score is 0.80 wheras in the second model (when using the count of the words) the accuracy score is 0.60. This makes sense because TF-IDF help to capture both the importance and relevance of a word whereas simply counting the occurance of words might include words that are too common across job postings which makes the prediction less accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df1e6c",
   "metadata": {},
   "source": [
    "## Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d98657",
   "metadata": {},
   "source": [
    "### Indeed, there might be some bias generated from only include the 1000 positive cases. I choice this way of dealing with the imbalanced data issue because it is the most intuitive and easiest way to quickly fix the issue. Future works can include performing other methods that tackle the imbalanced data issue such performing data augmentation, which can allow further verification of the results. Moreover, I also think it would be interesting see how having a addendum or not (as some of the cases do not have addendums--those cases are dropped in the very beggining) predict the case status."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
